Week 2: Testing Principles

Principles of Testing & Analysis:

    What: The qulity process
    Where: Focusing on problematic constructs and modules likely to contain bugs
    When: Performing testing as early and often as possible
    Who: Structuring organization for effective testing
    How: Strategies for effective testing

What: The Quality Process

Quality process: set of activities and responsabilities
    -focused primarily on ensuring adequate dependability
    -concerned with project schedule or with product usability?

The quality process provides a framework for
    -selecting and arranging activites
    -considering interactions and trade-offs with other important goals

Quality Goals:

Process qualities
    repeatability, timeliness, cost, CI

Product qualities
    internal qualities: reusability, manageability, maintainability, modifiability

    external qualities
        -Dependability qualities: availability, correctness, reliability, safety, robustness
        -usefulness qualities: usability, performance, security, portability, interoperability


Where: Error-Prone Aspects

Floating-point numbers
    Inherently imprecise. The imprecision may lead to invalid comparasions
    Sequences of computations may lose precision

Pointers (C/C++)
    Pointers refering to the wrong memory areas can corrupt data
    Aliasing  can make programs difficult to understand and change

Parallelism 
    Can result in subtle timing errors because of unforseen interaction parallel processes
    Can result in deadlock if synchronization is used incorrectly

Numeric Limits/ Boundaries
    very large values for integers / floats
    Boundary values for relational expressions

Interrupts
    Interupts can cause a critical operation to be terminated and make a program difficult to understand
    Interrupts are comparable to goto statements

Complex Boolean Expressions
    Nested Boolean operators can be difficult to understand

Casts and Conversions between Types
    Especially numeric types: can lose precision or overflow

80-20 rule for module testing:
    A small number of modules usually contain most of the defects discovered during pre-release testing.


Testing Principles - How

Divisibility: Dived and conquer
    Scope of Tests (unit, integration, system)
    Purpose of Tests (memory, performance)
    Testing Techniques (depending on the purpose)

Visibility
   Observability of inputs
   State Exposure
   Logging

Repeatability
    We want tests to always pass or always fail
    Tests that sometimes fail are called "flakey tests"
    Could be: bad test, bad program, bad environment
    //if the test requires external dependencies (ex: databases, filesystems),
    //we want to make sure that the state of db is in consistent state

Redundancy
    Most verification methods are unsound: they miss errors

Feedback
    Different apps have different "pain points"
    Update tests to more thoroughly test areas known to be problematic
    Lear which classes of bugs are most likely
    Work with developers to reduce systematic errors

V model

The V-model is a type of SDLC model where process executes in a sequential manner in V-shape.
It is also known as Verification and Validation model. 
It is based on the association of a testing phase for each corresponding development stage. 
Development of each step directly associated with the testing phase. 
The next phase starts only after completion of the previous phase 
i.e. for each development activity, there is a testing activity corresponding to it.

Verification: 
    It involves static analysis technique (review) done without executing code. 
    It is the process of evaluation of the product development phase to find whether specified requirements meet. 
    Answering "Are we building the product right?"

Validation: 
    It involves dynamic analysis technique (functional, non-functional), testing done by executing code.
    Validation is the process to evaluate the software after the completion of the development phase to determine whether software meets the customer expectations and requirements.
    Answering "Are we building the right product?"



Structural Testing

Black-box Testing vs White-box Testing
BB has no access to source code
WB has access to source code
Structural Testing is WB

Code Coverage
We have to test ideally each line of code at least once.

Why is structural testing important?
Running every test possible is usually impossible

Code Coverage Standards
    Statement
    Condition
    Decision
    Branch
    Condition/Decision
    Modified Condition/Decision
    Observable Modified Condition/Decision

Challenges in Structural Coverage
    Interprocedural and gross-level coverage of large O-O programs.
    Regression testing
    Late biding

Infeasibility Problem
    Reaching 100% coverage is often impossible



Mutation Testing

Mutation Testing is a type of software testing in which certain 
statements of the source code are changed/mutated
to check if the test cases are able to find errors in source code. 
The goal of Mutation Testing is ensuring the quality of test cases 
in terms of robustness that it should fail the mutated source code.

Program testing can be used to show the presence of bugs but not their absence.

Mutation Operators
    Booleans
    off by one
    switch variable nammes of the same type
    change (+-><==!=)



Week 3

What is a test plan?

Test Plan
A document describing the scope, approach,
resources, and schedule of intended testing activities.
It identifies test items, the features to be tested, the
testing tasks, who will do each task, and any risks
requiring contingency planning.

Components of a Test Plan

Testing approach/strategy
Scope (know your domain)
Schedule (10w after the build)
Resources/Test Environment (materials, equipment, servers, tools, qa team)
Entry and Exit Criteria
Requirements Matrix (for Traceability)
What is NOT tested
Test cases and scripts [separate docs]


Traceability

Tracing test cases to requirements

Tracing  requirements to test cases
    If a requirement changes, which test cases are affected?
    Are all requirements getting tested?

Tracing either requirements or test casses to software modules

Test Plan Activities
    Use a TP template, or design one
    List what cannot be tested
    Write only what you need
    Have the TP reviewed
    Make it a "living" document


Why we need a good test plan
    Organize, schedule, and manage testing effort
    Helps in writing test cases
    Improves communication between devs and management
    Measuring software quality is the intent (and must be planned)
    Developing good test sets takes planning
    Knowing when to stop
    More effective arguments when you have the facts

Concerns of Test Planning
    Not enough training
    Lack of customer/user involvement
    Not enough time
    Rapid change
    Lack of test tools
    Lack of management support

Test Planning is Important
    Creating a plaan and sticking to it makes it easier
    Ensure that everything is completed 
    Know when to stop
    Have facts to bolster arguments
    Say "No" to project release if you have to


Stages of Software Testing Process

4 categories of tests:

    Unit Test - WB completed by the devs
        -Unit Test Plan
    Design Verification Test
        -Integration Testing
        -Functional Testing
        -DVT Test Plan/Test Cases
    System Validation Test
        -System Test (test expected behavior)
        -Non-functional Testing(quality with wich we delivered the behavior, performance)
    Customer Acceptance Test
        -Customer acceptance test plan


Test (Status) Reports

Test Status Report
    How the test cycle is going
    Occures after each tresting cycle

Test Report
    How the entire testing effort went for a project/feature
    Occurs at end of testing

Should include:
    Evaluate how testing went/is going
    List what was tested
    List what was not tested, and why
    List still-open defects (some ask for all defects)
    Show the actual schedule
    Tell developers what works/doesn't

Why the Test (Status) Report

Two main reasons:
    Allow management and marketing to do their jobs
    Assist in process improvement

Test (Status) Reports
    Assessment of the current/final testing progress
    List what was tested
    List what wasn't tested
    List still-open defects
    List the schedule (actual and current)



Risk-based Test Planning

Importance of risk-based testing
    One of the purposes of testing is to reduce risk
    Determining that risk is the goal of risk-based testing

Definitions associated with risk
    Risk: Any potential loss to an org
    Components of risk: Impact/Loss and Likelihood/Probability
    Risk Analysis: Determining the impact and likelihood of various risks
    Risk Equation: Risk = Impact x Likelihood
    Risk Apetite: The amount of loss that management is willing to accept
    Risk Migration: The act of reducing risk

Nature of risk

Two components
    Impact
    Likelihood

Impact
    Depth
        Severity of damage
        Availability of workarounds

    Breadth
        Number (of systems/people) affected
        Cost of damage done

Categories of impact
    Finacnial
    Reputation
    Licenses
    Customer
    Employees
    Lives

Likelihood
    Possible factor for likelihood of failure
        Size of module
        Use of new (unproven) technology
        Prior error history
        Lack of skill experience
        Lack of motivation
        Inadequate processes
        Complex features or modules
        New modules
        Features transferred between developers
        Code that has not been unit tested
        Features using large or distributed development teams

Risk Mitigation 
    Risk avoidance
    
    Risk transfer (insurance, indemnification)
    
    Risk Management
        Loss prevention
        Crisis management
        Training

    ex: doing code review is a risk mitigation tech

Conventional Approach to Risk-based Testing

When all else fails, risk can help prioritize

Impact
    Test those features with the highest impact

Likelihood
    Test those features most likely to fail

Testing is our primary means of reducing risk

    Design your tests on two factors
        What can go wrong?
        What must go right?

